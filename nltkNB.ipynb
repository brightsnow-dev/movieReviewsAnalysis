{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "import pprint\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are a thousand movie reviews for both**\n",
    "\n",
    "- positive and\n",
    "- negetive\n",
    "\n",
    "**reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I need to store it as \n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    ('pos', ['good', 'awesome', ....]), \n",
    "    ('neg', ['ridiculous', 'horrible', ...])\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)\n",
    "            ]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other way to do it would be the normal way instead of this one liner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "document_dict = {\n",
    "    'pos': [],\n",
    "    'neg': []\n",
    "}\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        # this will store the list of words read from the particular file in fileid\n",
    "        raw_list = movie_reviews.words(fileid)\n",
    "        # cleaning the list using stopwords\n",
    "        word_list = [word for word in raw_list if word not in stop_words]\n",
    "        if category == 'pos':\n",
    "            document_dict['pos'].extend(word_list)\n",
    "        elif category == 'neg':\n",
    "            document_dict['neg'].extend(word_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the list of all words to store the most frequently occuring ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a frequency distribution of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 77717),\n",
       " ('the', 76529),\n",
       " ('.', 65876),\n",
       " ('a', 38106),\n",
       " ('and', 35576),\n",
       " ('of', 34123),\n",
       " ('to', 31937),\n",
       " (\"'\", 30585),\n",
       " ('is', 25195),\n",
       " ('in', 21822),\n",
       " ('s', 18513),\n",
       " ('\"', 17612),\n",
       " ('it', 16107),\n",
       " ('that', 15924),\n",
       " ('-', 15595),\n",
       " (')', 11781),\n",
       " ('(', 11664),\n",
       " ('as', 11378),\n",
       " ('with', 10792),\n",
       " ('for', 9961)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "all_words.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[\"hate\"]  ## counting the occurences of a single word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### will train only for the first 5000 top words in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_words = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding these feature words in documents, making our function would ease it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    feature = {}\n",
    "    for w in feature_words:\n",
    "        feature[w] = (w in words)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What the below one does is, before hand we had only words and its category. But not we have the feature set (along with a boolean value of whether it is one of the most frequently used words or not)of the same word and then the category.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_sets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = feature_sets[:1900]\n",
    "testing_set = feature_sets[1900:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't be telling the machine the category i.e. whether the document is a postive one or a negative one. We ask it to tell that to us. Then we compare it to the known category that we have and calculate how accurate it is.\n",
    "\n",
    "## Naive bayes algorithm\n",
    "\n",
    "It states that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "posterior = \\frac{PriorOccurences \\times likelihood}{CurrentEvidence}\n",
    "\\end{equation*}\n",
    "\n",
    "Here posterior is likelihood of occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO-DO: To build own naive bais algorithm\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes classifier accuracy percentage :  73.0\n"
     ]
    }
   ],
   "source": [
    "## Testing it's accuracy\n",
    "print(\"Naive bayes classifier accuracy percentage : \", (nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "                seamless = True              pos : neg    =      9.7 : 1.0\n",
      "                 conveys = True              pos : neg    =      9.0 : 1.0\n",
      "                  feeble = True              neg : pos    =      8.3 : 1.0\n",
      "              incoherent = True              neg : pos    =      8.3 : 1.0\n",
      "                 supreme = True              pos : neg    =      7.0 : 1.0\n",
      "            construction = True              pos : neg    =      7.0 : 1.0\n",
      "            effortlessly = True              pos : neg    =      7.0 : 1.0\n",
      "                observes = True              pos : neg    =      7.0 : 1.0\n",
      "              compensate = True              neg : pos    =      7.0 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.0 : 1.0\n",
      "                   kudos = True              pos : neg    =      6.6 : 1.0\n",
      "                    moss = True              pos : neg    =      6.3 : 1.0\n",
      "                obstacle = True              pos : neg    =      6.3 : 1.0\n",
      "                   dewey = True              pos : neg    =      6.3 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.3 : 1.0\n",
      "                  regard = True              pos : neg    =      6.2 : 1.0\n",
      "           embarrassment = True              neg : pos    =      6.2 : 1.0\n",
      "                  symbol = True              pos : neg    =      5.8 : 1.0\n",
      "               strengths = True              pos : neg    =      5.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now now, don't get too carried away here.\n",
    "\n",
    "The results are not that accurate right now. We will be working on that later on\n",
    "\n",
    "What the above feature set means is lets take **abysmal**, \n",
    "\n",
    "> **neg : pos    =      6.3 : 1.0**\n",
    "\n",
    "means that it appears **6.3** times more in **neg** reviews than in **pos** reviews\n",
    "\n",
    "## Saving the trained algorithm using **Pickle**\n",
    "\n",
    "We will be saving python objects so that we can quickly load them again.\n",
    "\n",
    "_Importing pickle at the top_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(\"naivebayes.pickle\", \"wb\") ## 'wb' tells to write it using bytes\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now use this classifier in the next file to classify documents**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
